{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extra Multi Modal Image Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1zSTMP7v4B2gOX1SnH9LwoDiWOsZR3U4V",
      "authorship_tag": "ABX9TyPH5kfGJm3XhjDimSq5wGWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75299099dc7c4717bf36ce0a7b16dd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1e8f3c391f44b9a8c47493ff19d4da0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84c2bbecf9664f84a7e0ea33a93c0a44",
              "IPY_MODEL_c16f794c3c4c44c2bb958d57f2ae1968",
              "IPY_MODEL_6edd70643dea4a9481b915ebd5cef74e"
            ]
          }
        },
        "e1e8f3c391f44b9a8c47493ff19d4da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84c2bbecf9664f84a7e0ea33a93c0a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a6566e54cda471aa1c92df24d689b27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0338680386fc42c7806283e7b95470ba"
          }
        },
        "c16f794c3c4c44c2bb958d57f2ae1968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d874d36de35e4d18835ac886ee289f21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241627721,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241627721,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4323903234b14c80a1ac1b83b84e05d6"
          }
        },
        "6edd70643dea4a9481b915ebd5cef74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5bb35938d2654a30a649019573980d6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:03&lt;00:00, 71.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3d5496cabba489e8aa9b622d5b2814c"
          }
        },
        "5a6566e54cda471aa1c92df24d689b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0338680386fc42c7806283e7b95470ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d874d36de35e4d18835ac886ee289f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4323903234b14c80a1ac1b83b84e05d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bb35938d2654a30a649019573980d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3d5496cabba489e8aa9b622d5b2814c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosh98/AICS_LT2318_H21/blob/main/Extra/Extra_Case_MMBT_Large.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation of Supervised Multimodal Bitransformers for Classifying Images and Text**\n",
        "\n",
        "https://arxiv.org/pdf/1909.02950.pdf\n",
        "\n",
        "Inspiration From : https://github.com/facebookresearch/mmbt\n",
        "(Note: their repository has missing code \"fragments\" )\n",
        "\n",
        "Replicated for a **Binary** Pipeline\n",
        "\n",
        "![clip.PNG](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "nel-Oc8xlzBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Data"
      ],
      "metadata": {
        "id": "sM5xrywBCnzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Test_Cases.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EHqEp3Xy2XD",
        "outputId": "ed2e82f2-d332-409e-8087-8b323e16856c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Test_Cases.zip\n",
            "  inflating: Test Cases/same_text_diff_image.jsonl  \n",
            "  inflating: Test Cases/shuffled.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Link\n",
        "\n",
        "!unzip /content/drive/MyDrive/hateful_memes.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fcWTPdkeCl8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------"
      ],
      "metadata": {
        "id": "aKAEpAuYCtl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Necessary Packages\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "id": "Dj_INABmmx9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------\n",
        "\n",
        "## Image Embeddings Functions\n"
      ],
      "metadata": {
        "id": "Yh9eqIwLw_Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Image Encoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.args = args\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        self.model = nn.Sequential(*modules)\n",
        "\n",
        "        pool_func = (\n",
        "            nn.AdaptiveAvgPool2d\n",
        "            if args.img_embed_pool_type == \"avg\"\n",
        "            else nn.AdaptiveMaxPool2d\n",
        "        )\n",
        "\n",
        "        if args.num_image_embeds in [1, 2, 3, 5, 7]:\n",
        "            self.pool = pool_func((args.num_image_embeds, 1))\n",
        "        elif args.num_image_embeds == 4:\n",
        "            self.pool = pool_func((2, 2))\n",
        "        elif args.num_image_embeds == 6:\n",
        "            self.pool = pool_func((3, 2))\n",
        "        elif args.num_image_embeds == 8:\n",
        "            self.pool = pool_func((4, 2))\n",
        "        elif args.num_image_embeds == 9:\n",
        "            self.pool = pool_func((3, 3))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Bx3x224x224 -> Bx2048x7x7 -> Bx2048xN -> BxNx2048\n",
        "        out = self.pool(self.model(x))\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        return out  # BxNx2048\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMQI_JvYqG_i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Classifier\n",
        "\n",
        "\n",
        "class ImageClf(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(ImageClf, self).__init__()\n",
        "        self.args = args\n",
        "        self.img_encoder = ImageEncoder(args)\n",
        "        self.clf = nn.Linear(args.img_hidden_sz * args.num_image_embeds, args.n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.img_encoder(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        out = self.clf(x)\n",
        "        return out\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "N1XmoG0Svp3L",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# Multi Modal BERT\n"
      ],
      "metadata": {
        "id": "n_V89xGxqDB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MMBERT ImageEmbeddings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "\n",
        "class ImageBertEmbeddings(nn.Module):\n",
        "  def __init__(self,args,embeddings):\n",
        "    super(ImageBertEmbeddings,self).__init__()\n",
        "    self.args = args\n",
        "    self.img_embeddings = nn.Linear(args.img_hidden_sz, args.hidden_sz)\n",
        "    self.position_embeddings =embeddings.position_embeddings\n",
        "    self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "    self.word_embeddings = embeddings.word_embeddings\n",
        "    self.LayerNorm = embeddings.LayerNorm\n",
        "    self.dropout = nn.Dropout(p=args.dropout)\n",
        "\n",
        "  def forward(self, input_imgs, token_type_ids):\n",
        "        bsz = input_imgs.size(0)\n",
        "        seq_length = self.args.num_image_embeds + 2  # +2 for CLS and SEP Token\n",
        "\n",
        "        cls_id = torch.LongTensor([self.args.vocab.stoi[\"[CLS]\"]]).cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(bsz, 1)\n",
        "        cls_token_embeds = self.word_embeddings(cls_id)\n",
        "\n",
        "        sep_id = torch.LongTensor([self.args.vocab.stoi[\"[SEP]\"]]).cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(bsz, 1)\n",
        "        sep_token_embeds = self.word_embeddings(sep_id)\n",
        "\n",
        "        imgs_embeddings = self.img_embeddings(input_imgs)\n",
        "        token_embeddings = torch.cat(\n",
        "            [cls_token_embeds, imgs_embeddings, sep_token_embeds], dim=1\n",
        "        )\n",
        "\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long).cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(bsz, seq_length)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        embeddings = token_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        return embeddings\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "snME7lCLv7aF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MM BertEncoder\n",
        "\n",
        "class MultimodalBertEncoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(MultimodalBertEncoder, self).__init__()\n",
        "        self.args = args\n",
        "        bert = BertModel.from_pretrained(args.bert_model)\n",
        "        self.txt_embeddings = bert.embeddings\n",
        "\n",
        "        if args.task == \"vsnli\":\n",
        "            ternary_embeds = nn.Embedding(3, args.hidden_sz)\n",
        "            ternary_embeds.weight.data[:2].copy_(\n",
        "                bert.embeddings.token_type_embeddings.weight\n",
        "            )\n",
        "            ternary_embeds.weight.data[2].copy_(\n",
        "                bert.embeddings.token_type_embeddings.weight.data.mean(dim=0)\n",
        "            )\n",
        "            self.txt_embeddings.token_type_embeddings = ternary_embeds\n",
        "\n",
        "        self.img_embeddings = ImageBertEmbeddings(args, self.txt_embeddings)\n",
        "        self.img_encoder = ImageEncoder(args)\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(args.hidden_sz, args.n_classes)\n",
        "\n",
        "    def forward(self, input_txt, attention_mask, segment, input_img):\n",
        "        bsz = input_txt.size(0)\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                torch.ones(bsz, self.args.num_image_embeds + 2).long().cuda(),\n",
        "                attention_mask,\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        img_tok = (\n",
        "            torch.LongTensor(input_txt.size(0), self.args.num_image_embeds + 2)\n",
        "            .fill_(0)\n",
        "            .cuda()\n",
        "        )\n",
        "        img = self.img_encoder(input_img)  # BxNx3x224x224 -> BxNx2048\n",
        "        img_embed_out = self.img_embeddings(img, img_tok)\n",
        "        txt_embed_out = self.txt_embeddings(input_txt, segment)\n",
        "\n",
        "        encoder_input = torch.cat([img_embed_out, txt_embed_out], 1)  # Bx(TEXT+IMG)xHID\n",
        "\n",
        "        encoded_layers = self.encoder(\n",
        "            encoder_input, extended_attention_mask, output_all_encoded_layers=False\n",
        "        )\n",
        "\n",
        "        return self.pooler(encoded_layers[-1])\n"
      ],
      "metadata": {
        "id": "F8GlEernBt8Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MultiModal BERT Classifier Layer\n",
        "\n",
        "class MultimodalBertClf(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(MultimodalBertClf, self).__init__()\n",
        "        self.args = args\n",
        "        self.enc = MultimodalBertEncoder(args)\n",
        "        self.clf = nn.Linear(args.hidden_sz, args.n_classes)\n",
        "\n",
        "    def forward(self, txt, mask, segment, img):\n",
        "        x = self.enc(txt, mask, segment, img)\n",
        "        return self.clf(x)\n",
        "  "
      ],
      "metadata": {
        "id": "aGh6Z0a15l0G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "##Helper Functions"
      ],
      "metadata": {
        "id": "TAIVOWfq-TFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title criterion\n",
        "def get_criterion(args):\n",
        "    if args.task_type == \"multilabel\":\n",
        "        if args.weight_classes:\n",
        "            freqs = [args.label_freqs[l] for l in args.labels]\n",
        "            label_weights = (torch.FloatTensor(freqs) / args.train_data_len) ** -1\n",
        "            criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights.cuda())\n",
        "        else:\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    return criterion"
      ],
      "metadata": {
        "id": "Z-LdZrqG-YW7",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bert Optimizer\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "\n",
        "def get_optimizer(model, args):\n",
        "    if args.model in [\"bert\", \"concatbert\", \"mmbt\"]:\n",
        "        total_steps = (\n",
        "            args.train_data_len\n",
        "            / args.batch_sz\n",
        "            / args.gradient_accumulation_steps\n",
        "            * args.max_epochs\n",
        "        )\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "            {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "        ]\n",
        "        optimizer = BertAdam(\n",
        "            optimizer_grouped_parameters,\n",
        "            lr=args.lr,\n",
        "            warmup=args.warmup,\n",
        "            t_total=total_steps,\n",
        "        )\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "  \n",
        "      "
      ],
      "metadata": {
        "id": "VixYw60NJtSg",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title scheduler\n",
        "def get_scheduler(optimizer, args):\n",
        "    return optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", patience=args.lr_patience, verbose=True, factor=args.lr_factor\n",
        "    )"
      ],
      "metadata": {
        "id": "QPnY77HMLily",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title loggers\n",
        "\n",
        "import logging\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "class LogFormatter:\n",
        "    def __init__(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def format(self, record):\n",
        "        elapsed_seconds = round(record.created - self.start_time)\n",
        "\n",
        "        prefix = \"%s - %s - %s\" % (\n",
        "            record.levelname,\n",
        "            time.strftime(\"%x %X\"),\n",
        "            timedelta(seconds=elapsed_seconds),\n",
        "        )\n",
        "        message = record.getMessage()\n",
        "        message = message.replace(\"\\n\", \"\\n\" + \" \" * (len(prefix) + 3))\n",
        "        return \"%s - %s\" % (prefix, message)\n",
        "\n",
        "\n",
        "def create_logger(filepath, args):\n",
        "    # create log formatter\n",
        "    log_formatter = LogFormatter()\n",
        "\n",
        "    # create file handler and set level to debug\n",
        "    file_handler = logging.FileHandler(filepath, \"a\")\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    file_handler.setFormatter(log_formatter)\n",
        "\n",
        "    # create console handler and set level to info\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_handler.setFormatter(log_formatter)\n",
        "\n",
        "    # create logger and set level to debug\n",
        "    logger = logging.getLogger()\n",
        "    logger.handlers = []\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    logger.propagate = False\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    # reset logger elapsed time\n",
        "    def reset_time():\n",
        "        log_formatter.start_time = time.time()\n",
        "\n",
        "    logger.reset_time = reset_time\n",
        "\n",
        "    logger.info(\n",
        "        \"\\n\".join(\n",
        "            \"%s: %s\" % (k, str(v))\n",
        "            for k, v in sorted(dict(vars(args)).items(), key=lambda x: x[0])\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E6mYkn0TyP2a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper Functions: \n",
        "#\n",
        "\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_path, filename=\"checkpoint.pt\"):\n",
        "    filename = os.path.join(checkpoint_path, filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, os.path.join(checkpoint_path, \"model_best.pt\"))\n",
        "\n",
        "\n",
        "def load_checkpoint(model, path):\n",
        "    best_checkpoint = torch.load(path)\n",
        "    model.load_state_dict(best_checkpoint[\"state_dict\"])\n",
        "\n",
        "\n",
        "def truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\n",
        "    Copied from https://github.com/huggingface/pytorch-pretrained-BERT\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, args):\n",
        "    if args.task_type == \"multilabel\":\n",
        "        with open(os.path.join(args.savedir, \"test_labels_pred.txt\"), \"w\") as fw:\n",
        "            fw.write(\n",
        "                \"\\n\".join([\" \".join([\"1\" if x else \"0\" for x in p]) for p in preds])\n",
        "            )\n",
        "        with open(os.path.join(args.savedir, \"test_labels_gold.txt\"), \"w\") as fw:\n",
        "            fw.write(\n",
        "                \"\\n\".join([\" \".join([\"1\" if x else \"0\" for x in t]) for t in tgts])\n",
        "            )\n",
        "        with open(os.path.join(args.savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "            fw.write(\" \".join([l for l in args.labels]))\n",
        "\n",
        "    else:\n",
        "        with open(os.path.join(args.savedir, \"test_labels_pred.txt\"), \"w\") as fw:\n",
        "            fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "        with open(os.path.join(args.savedir, \"test_labels_gold.txt\"), \"w\") as fw:\n",
        "            fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "        with open(os.path.join(args.savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "            fw.write(\" \".join([str(l) for l in args.labels]))\n",
        "\n",
        "\n",
        "def log_metrics(set_name, metrics, args, logger):\n",
        "    if args.task_type == \"multilabel\":\n",
        "        logger.info(\n",
        "            \"{}: Loss: {:.5f} | Macro F1 {:.5f} | Micro F1: {:.5f}\".format(\n",
        "                set_name, metrics[\"loss\"], metrics[\"macro_f1\"], metrics[\"micro_f1\"]\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        logger.info(\n",
        "            \"{}: Loss: {:.5f} | Acc: {:.5f}\".format(\n",
        "                set_name, metrics[\"loss\"], metrics[\"acc\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def numpy_seed(seed, *addl_seeds):\n",
        "    \"\"\"Context manager which seeds the NumPy PRNG with the specified seed and\n",
        "    restores the state afterward\"\"\"\n",
        "    if seed is None:\n",
        "        yield\n",
        "        return\n",
        "    if len(addl_seeds) > 0:\n",
        "        seed = int(hash((seed, *addl_seeds)) % 1e6)\n",
        "    state = np.random.get_state()\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        np.random.set_state(state)\n",
        "\n",
        "\n",
        "class JsonlDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, transforms, vocab, args):\n",
        "        self.data = [json.loads(l) for l in open(data_path)]\n",
        "        self.data_dir = os.path.dirname(data_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.args = args\n",
        "        self.vocab = vocab\n",
        "        self.n_classes = len(args.labels)\n",
        "        self.text_start_token = [\"[CLS]\"] if args.model != \"mmbt\" else [\"[SEP]\"]\n",
        "\n",
        "        with numpy_seed(0):\n",
        "            for row in self.data:\n",
        "                if np.random.random() < args.drop_img_percent:\n",
        "                    row[\"img\"] = None\n",
        "\n",
        "        self.max_seq_len = args.max_seq_len\n",
        "        if args.model == \"mmbt\":\n",
        "            self.max_seq_len -= args.num_image_embeds\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.args.task == \"vsnli\":\n",
        "            sent1 = self.tokenizer(self.data[index][\"sentence1\"])\n",
        "            sent2 = self.tokenizer(self.data[index][\"sentence2\"])\n",
        "            truncate_seq_pair(sent1, sent2, self.args.max_seq_len - 3)\n",
        "            sentence = self.text_start_token + sent1 + [\"[SEP]\"] + sent2 + [\"[SEP]\"]\n",
        "            segment = torch.cat(\n",
        "                [torch.zeros(2 + len(sent1)), torch.ones(len(sent2) + 1)]\n",
        "            )\n",
        "        else:\n",
        "            #change to shuffled when doing tests\n",
        "            sentence = (\n",
        "                self.text_start_token\n",
        "                + self.tokenizer(self.data[index][\"Shuffled\"])[\n",
        "                    : (self.args.max_seq_len - 1)\n",
        "                ]\n",
        "            )\n",
        "            segment = torch.zeros(len(sentence))\n",
        "\n",
        "        sentence = torch.LongTensor(\n",
        "            [\n",
        "                self.vocab.stoi[w] if w in self.vocab.stoi else self.vocab.stoi[\"[UNK]\"]\n",
        "                for w in sentence\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if self.args.task_type == \"multilabel\":\n",
        "            label = torch.zeros(self.n_classes)\n",
        "            label[\n",
        "                [self.args.labels.index(tgt) for tgt in self.data[index][\"label\"]]\n",
        "            ] = 1\n",
        "        else:\n",
        "            label = torch.LongTensor(\n",
        "                [self.args.labels.index(self.data[index][\"label\"])]\n",
        "            )\n",
        "\n",
        "        image = None\n",
        "        if self.args.model in [\"img\", \"concatbow\", \"concatbert\", \"mmbt\"]:\n",
        "            if self.data[index][\"img\"]:\n",
        "                image = Image.open(\n",
        "                    os.path.join(self.data_dir, self.data[index][\"img\"])\n",
        "                ).convert(\"RGB\")\n",
        "            else:\n",
        "                image = Image.fromarray(128 * np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        if self.args.model == \"mmbt\":\n",
        "            # The first SEP is part of Image Token.\n",
        "            segment = segment[1:]\n",
        "            sentence = sentence[1:]\n",
        "            # The first segment (0) is of images.\n",
        "            segment += 1\n",
        "\n",
        "        return sentence, segment, image, label\n",
        "\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi, self.itos, self.vocab_sz = {}, [], 0\n",
        "        else:\n",
        "            self.stoi = {\n",
        "                w: i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_sz = len(self.itos)\n",
        "\n",
        "    def add(self, words):\n",
        "        cnt = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w] = cnt\n",
        "            self.itos.append(w)\n",
        "            cnt += 1\n",
        "        self.vocab_sz = len(self.itos)\n",
        "\n",
        "\n",
        "def get_transforms(args):\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def get_labels_and_frequencies(path):\n",
        "    label_freqs = Counter()\n",
        "    data_labels = [json.loads(line)[\"label\"] for line in open(path)]\n",
        "    if type(data_labels[0]) == list:\n",
        "        for label_row in data_labels:\n",
        "            label_freqs.update(label_row)\n",
        "    else:\n",
        "        label_freqs.update(data_labels)\n",
        "\n",
        "    return list(label_freqs.keys()), label_freqs\n",
        "\n",
        "\n",
        "def get_glove_words(path):\n",
        "    word_list = []\n",
        "    for line in open(path):\n",
        "        w, _ = line.split(\" \", 1)\n",
        "        word_list.append(w)\n",
        "    return word_list\n",
        "\n",
        "\n",
        "def get_vocab(args):\n",
        "    vocab = Vocab()\n",
        "    if args.model in [\"bert\", \"mmbt\", \"concatbert\"]:\n",
        "        bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            args.bert_model, do_lower_case=True\n",
        "        )\n",
        "        vocab.stoi = bert_tokenizer.vocab\n",
        "        vocab.itos = bert_tokenizer.ids_to_tokens\n",
        "        vocab.vocab_sz = len(vocab.itos)\n",
        "\n",
        "    else:\n",
        "        word_list = get_glove_words(args.glove_path)\n",
        "        vocab.add(word_list)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def collate_fn(batch, args):\n",
        "    lens = [len(row[0]) for row in batch]\n",
        "    bsz, max_seq_len = len(batch), max(lens)\n",
        "\n",
        "    mask_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "    text_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "    segment_tensor = torch.zeros(bsz, max_seq_len).long()\n",
        "\n",
        "    img_tensor = None\n",
        "    if args.model in [\"img\", \"concatbow\", \"concatbert\", \"mmbt\"]:\n",
        "        img_tensor = torch.stack([row[2] for row in batch])\n",
        "\n",
        "    if args.task_type == \"multilabel\":\n",
        "        # Multilabel case\n",
        "        tgt_tensor = torch.stack([row[3] for row in batch])\n",
        "    else:\n",
        "        # Single Label case\n",
        "        tgt_tensor = torch.cat([row[3] for row in batch]).long()\n",
        "\n",
        "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
        "        tokens, segment = input_row[:2]\n",
        "        text_tensor[i_batch, :length] = tokens\n",
        "        segment_tensor[i_batch, :length] = segment\n",
        "        mask_tensor[i_batch, :length] = 1\n",
        "\n",
        "    return text_tensor, segment_tensor, mask_tensor, img_tensor, tgt_tensor\n",
        "\n",
        "\n",
        "def get_data_loaders(args):\n",
        "    tokenizer = (\n",
        "        BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True).tokenize\n",
        "        if args.model in [\"bert\", \"mmbt\", \"concatbert\"]\n",
        "        else str.split\n",
        "    )\n",
        "\n",
        "    transforms = get_transforms(args)\n",
        "\n",
        "    args.labels, args.label_freqs = get_labels_and_frequencies(\n",
        "        os.path.join(args.data_path, \"train.jsonl\")\n",
        "    )\n",
        "    vocab = get_vocab(args)\n",
        "    args.vocab = vocab\n",
        "    args.vocab_sz = vocab.vocab_sz\n",
        "    args.n_classes = len(args.labels)\n",
        "\n",
        "    train = JsonlDataset(\n",
        "        os.path.join(args.data_path, \"train.jsonl\"),\n",
        "        tokenizer,\n",
        "        transforms,\n",
        "        vocab,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "    args.train_data_len = len(train)\n",
        "\n",
        "    #/content/hateful_memes/train.jsonl\n",
        "    dev = JsonlDataset(\n",
        "        os.path.join(args.data_path,  \"dev_seen.jsonl\"),\n",
        "        tokenizer,\n",
        "        transforms,\n",
        "        vocab,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "    collate = functools.partial(collate_fn, args=args)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train,\n",
        "        batch_size=args.batch_sz,\n",
        "        shuffle=True,\n",
        "        num_workers=args.n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        dev,\n",
        "        batch_size=args.batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=args.n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    test_set = JsonlDataset(\n",
        "        os.path.join(args.data_path, \"test_seen.jsonl\"),\n",
        "        tokenizer,\n",
        "        transforms,\n",
        "        vocab,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_set,\n",
        "        batch_size=args.batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=args.n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "\n",
        "    if args.task == \"vsnli\":\n",
        "        test_hard = JsonlDataset(\n",
        "            os.path.join(args.data_path,  \"test_hard.jsonl\"),\n",
        "            tokenizer,\n",
        "            transforms,\n",
        "            vocab,\n",
        "            args,\n",
        "        )\n",
        "\n",
        "        test_hard_loader = DataLoader(\n",
        "            test_hard,\n",
        "            batch_size=args.batch_sz,\n",
        "            shuffle=False,\n",
        "            num_workers=args.n_workers,\n",
        "            collate_fn=collate,\n",
        "        )\n",
        "\n",
        "        test = {\"test\": test_loader, \"test_hard\": test_hard_loader}\n",
        "\n",
        "    else:\n",
        "        test_gt = JsonlDataset(\n",
        "            os.path.join(args.data_path,  \"test_unseen.jsonl\"),\n",
        "            tokenizer,\n",
        "            transforms,\n",
        "            vocab,\n",
        "            args,\n",
        "        )\n",
        "\n",
        "        test_gt_loader = DataLoader(\n",
        "            test_gt,\n",
        "            batch_size=args.batch_sz,\n",
        "            shuffle=False,\n",
        "            num_workers=args.n_workers,\n",
        "            collate_fn=collate,\n",
        "        )\n",
        "\n",
        "        test = {\n",
        "            \"test\": test_loader,\n",
        "            \"test_gt\": test_gt_loader,\n",
        "        }\n",
        "\n",
        "    return train_loader, val_loader, test\n"
      ],
      "metadata": {
        "id": "8422qQylxOxq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title model forward during training\n",
        "\n",
        "def model_forward(i_epoch, model, args, criterion, batch):\n",
        "    txt, segment, mask, img, tgt = batch\n",
        "\n",
        "    freeze_img = i_epoch < args.freeze_img\n",
        "    freeze_txt = i_epoch < args.freeze_txt\n",
        "\n",
        "    if args.model == \"bow\":\n",
        "        txt = txt.cuda()\n",
        "        out = model(txt)\n",
        "    elif args.model == \"img\":\n",
        "        img = img.cuda()\n",
        "        out = model(img)\n",
        "    elif args.model == \"concatbow\":\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        out = model(txt, img)\n",
        "    elif args.model == \"bert\":\n",
        "        txt, mask, segment = txt.cuda(), mask.cuda(), segment.cuda()\n",
        "        out = model(txt, mask, segment)\n",
        "    elif args.model == \"concatbert\":\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "        out = model(txt, mask, segment, img)\n",
        "    else:\n",
        "        assert args.model == \"mmbt\"\n",
        "        for param in model.enc.img_encoder.parameters():\n",
        "            param.requires_grad = not freeze_img\n",
        "        for param in model.enc.encoder.parameters():\n",
        "            param.requires_grad = not freeze_txt\n",
        "\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "        out = model(txt, mask, segment, img)\n",
        "\n",
        "    tgt = tgt.cuda()\n",
        "    loss = criterion(out, tgt)\n",
        "    return loss, out, tgt\n"
      ],
      "metadata": {
        "id": "TdXc5DkiMSmj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "# Training\n",
        "\n",
        "Example: \n",
        "\n",
        "\n",
        "```\n",
        "python mmbt/train.py --batch_sz 4 --gradient_accumulation_steps 40 \\\n",
        " --savedir /path/to/savedir/ --name mmbt_model_run \\\n",
        " --data_path /path/to/datasets/ \\\n",
        " --task food101 --task_type classification \\\n",
        " --model mmbt --num_image_embeds 3 --freeze_txt 5 --freeze_img 3  \\\n",
        " --patience 5 --dropout 0.1 --lr 5e-05 --warmup 0.1 --max_epochs 100 --seed 1\n",
        "```\n",
        "\n",
        "\n",
        "These are the parametres you should tinker with when making you own model.\n",
        "\n"
      ],
      "metadata": {
        "id": "RTCjosE4otaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title model_eval()\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def model_eval(i_epoch, data, model, args, criterion, store_preds=False):\n",
        "    losses, preds, tgts = [], [], []\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, args, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            if args.task_type == \"multilabel\":\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy() > 0.5\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "\n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    if args.task_type == \"multilabel\":\n",
        "        tgts = np.vstack(tgts)\n",
        "        preds = np.vstack(preds)\n",
        "        metrics[\"macro_f1\"] = f1_score(tgts, preds, average=\"macro\")\n",
        "        metrics[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
        "    else:\n",
        "        tgts = [l for sl in tgts for l in sl]\n",
        "        preds = [l for sl in preds for l in sl]\n",
        "        metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "        #metrics[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
        "        #metrics[\"report\"] = classification_report(tgts, preds, output_dict= True)\n",
        "        #print(classification_report(tgts, preds))\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, args)\n",
        "\n",
        "    #return metrics,preds,tgts\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "zDf1a3euucTu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(args):\n",
        "    return MultimodalBertClf(args)"
      ],
      "metadata": {
        "id": "eT5ScO880a0e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train function\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    set_seed(args.seed)\n",
        "    args.savedir = os.path.join(args.savedir, args.name)\n",
        "    os.makedirs(args.savedir, exist_ok=True)\n",
        "\n",
        "    train_loader, val_loader, test_loaders = get_data_loaders(args)\n",
        "\n",
        "    model = get_model(args)\n",
        "    criterion = get_criterion(args) #criteria for loss\n",
        "    optimizer = get_optimizer(model, args) #adam optimizer\n",
        "    scheduler = get_scheduler(optimizer, args) #Scheduler\n",
        "\n",
        "    logger = create_logger(\"%s/logfile.log\" % args.savedir, args)\n",
        "    logger.info(model)\n",
        "    model.cuda()\n",
        "\n",
        "    torch.save(args, os.path.join(args.savedir, \"args.pt\"))\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    if os.path.exists(os.path.join(args.savedir, \"checkpoint.pt\")):\n",
        "        checkpoint = torch.load(os.path.join(args.savedir, \"checkpoint.pt\"))\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        n_no_improve = checkpoint[\"n_no_improve\"]\n",
        "        best_metric = checkpoint[\"best_metric\"]\n",
        "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "\n",
        "    logger.info(\"Training..\")\n",
        "    \n",
        "    for i_epoch in  range(start_epoch, args.max_epochs) :\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, args, criterion, batch)\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % args.gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, args, criterion)\n",
        "        logger.info(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        log_metrics(\"Val\", metrics, args, logger)\n",
        "\n",
        "        tuning_metric = (\n",
        "            metrics[\"micro_f1\"] if args.task_type == \"multilabel\" else metrics[\"acc\"]\n",
        "        )\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "\n",
        "        save_checkpoint(\n",
        "            {\n",
        "                \"epoch\": i_epoch + 1,\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict(),\n",
        "                \"n_no_improve\": n_no_improve,\n",
        "                \"best_metric\": best_metric,\n",
        "            },\n",
        "            is_improvement,\n",
        "            args.savedir,\n",
        "        )\n",
        "\n",
        "        if n_no_improve >= args.patience:\n",
        "            logger.info(\"No improvement. Breaking out of loop.\")\n",
        "            break\n",
        "\n",
        "    load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "    model.eval()\n",
        "    for test_name, test_loader in test_loaders.items():\n",
        "        test_metrics = model_eval(\n",
        "            np.inf, test_loader, model, args, criterion, store_preds=True\n",
        "        )\n",
        "        log_metrics(f\"Test - {test_name}\", test_metrics, args, logger)\n"
      ],
      "metadata": {
        "id": "z7zHliLY0ke0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Train Models\")\n",
        "\n",
        "parser.add_argument(\"--batch_sz\", type=int, default=8)\n",
        "parser.add_argument(\"--bert_model\", type=str, default=\"bert-large-uncased\", choices=[\"bert-base-uncased\", \"bert-large-uncased\"])\n",
        "parser.add_argument(\"--data_path\", type=str, default=\"/content/hateful_memes\")\n",
        "parser.add_argument(\"--drop_img_percent\", type=float, default=0.0)\n",
        "parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
        "parser.add_argument(\"--embed_sz\", type=int, default=100)\n",
        "parser.add_argument(\"--freeze_img\", type=int, default=0)\n",
        "parser.add_argument(\"--freeze_txt\", type=int, default=0)\n",
        "parser.add_argument(\"--glove_path\", type=str, default=\"/path/to/glove_embeds/glove.840B.300d.txt\")\n",
        "parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=20)\n",
        "parser.add_argument(\"--hidden\", nargs=\"*\", type=int, default=[])\n",
        "parser.add_argument(\"--hidden_sz\", type=int, default=1024)\n",
        "parser.add_argument(\"--img_embed_pool_type\", type=str, default=\"avg\", choices=[\"max\", \"avg\"])\n",
        "parser.add_argument(\"--img_hidden_sz\", type=int, default=2048)\n",
        "parser.add_argument(\"--include_bn\", type=int, default=True)\n",
        "parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
        "parser.add_argument(\"--lr_factor\", type=float, default=0.5)\n",
        "parser.add_argument(\"--lr_patience\", type=int, default=2)\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--max_seq_len\", type=int, default=512)\n",
        "parser.add_argument(\"--model\", type=str, default=\"mmbt\", choices=[\"bow\", \"img\", \"bert\", \"concatbow\", \"concatbert\", \"mmbt\"])\n",
        "parser.add_argument(\"--n_workers\", type=int, default=12)\n",
        "parser.add_argument(\"--n_classes\", type=int, default=2)\n",
        "\n",
        "parser.add_argument(\"--name\", type=str, default=\"mmbt\")\n",
        "\n",
        "parser.add_argument(\"--num_image_embeds\", type=int, default=1)\n",
        "parser.add_argument(\"--patience\", type=int, default=5)\n",
        "parser.add_argument(\"--savedir\", type=str, default=\"/content/\")\n",
        "parser.add_argument(\"--seed\", type=int, default=123)\n",
        "parser.add_argument(\"--task\", type=str, default=\"mmimdb\", choices=[\"mmimdb\", \"vsnli\", \"food101\"])\n",
        "parser.add_argument(\"--task_type\", type=str, default=\"classification\", choices=[\"multilabel\", \"classification\"])\n",
        "parser.add_argument(\"--warmup\", type=float, default=0.1)\n",
        "parser.add_argument(\"--weight_classes\", type=int, default=1)\n",
        "\n",
        "args, remaining_args = parser.parse_known_args()"
      ],
      "metadata": {
        "id": "xwOq7a-erRqy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx7MfMCv59lt",
        "outputId": "65884410-0462-409f-e63d-8d3f4a0bf468"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(batch_sz=8, bert_model='bert-large-uncased', data_path='/content/hateful_memes', drop_img_percent=0.0, dropout=0.1, embed_sz=100, freeze_img=0, freeze_txt=0, glove_path='/path/to/glove_embeds/glove.840B.300d.txt', gradient_accumulation_steps=20, hidden=[], hidden_sz=1024, img_embed_pool_type='avg', img_hidden_sz=2048, include_bn=True, lr=0.0001, lr_factor=0.5, lr_patience=2, max_epochs=10, max_seq_len=512, model='mmbt', n_classes=2, n_workers=12, name='mmbt', num_image_embeds=1, patience=5, savedir='/content/', seed=123, task='mmimdb', task_type='classification', warmup=0.1, weight_classes=1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeepMIzdCXFg",
        "outputId": "7acf0db6-00d4-4e32-ecee-c7b7532905d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-f',\n",
              " '/root/.local/share/jupyter/runtime/kernel-127b0e50-89bb-4ecb-978b-38ebcb941633.json']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is where you run! \n",
        "# **RUN**"
      ],
      "metadata": {
        "id": "-rDSzX-1CJQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IvXv50Y66mxl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75299099dc7c4717bf36ce0a7b16dd2a",
            "e1e8f3c391f44b9a8c47493ff19d4da0",
            "84c2bbecf9664f84a7e0ea33a93c0a44",
            "c16f794c3c4c44c2bb958d57f2ae1968",
            "6edd70643dea4a9481b915ebd5cef74e",
            "5a6566e54cda471aa1c92df24d689b27",
            "0338680386fc42c7806283e7b95470ba",
            "d874d36de35e4d18835ac886ee289f21",
            "4323903234b14c80a1ac1b83b84e05d6",
            "5bb35938d2654a30a649019573980d6d",
            "d3d5496cabba489e8aa9b622d5b2814c"
          ]
        },
        "id": "CqKkM-mY9IAf",
        "outputId": "11920c02-8077-4a3f-ea18-b9461a3ea3b9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 319188.74B/s]\n",
            "100%|██████████| 1248501532/1248501532 [01:39<00:00, 12537193.44B/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75299099dc7c4717bf36ce0a7b16dd2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 01/16/22 10:40:31 - 0:00:00 - batch_sz: 8\n",
            "                                     bert_model: bert-large-uncased\n",
            "                                     data_path: /content/hateful_memes\n",
            "                                     drop_img_percent: 0.0\n",
            "                                     dropout: 0.1\n",
            "                                     embed_sz: 100\n",
            "                                     freeze_img: 0\n",
            "                                     freeze_txt: 0\n",
            "                                     glove_path: /path/to/glove_embeds/glove.840B.300d.txt\n",
            "                                     gradient_accumulation_steps: 20\n",
            "                                     hidden: []\n",
            "                                     hidden_sz: 1024\n",
            "                                     img_embed_pool_type: avg\n",
            "                                     img_hidden_sz: 2048\n",
            "                                     include_bn: True\n",
            "                                     label_freqs: Counter({0: 5481, 1: 3019})\n",
            "                                     labels: [0, 1]\n",
            "                                     lr: 0.0001\n",
            "                                     lr_factor: 0.5\n",
            "                                     lr_patience: 2\n",
            "                                     max_epochs: 10\n",
            "                                     max_seq_len: 512\n",
            "                                     model: mmbt\n",
            "                                     n_classes: 2\n",
            "                                     n_workers: 12\n",
            "                                     name: mmbt\n",
            "                                     num_image_embeds: 1\n",
            "                                     patience: 5\n",
            "                                     savedir: /content/mmbt\n",
            "                                     seed: 123\n",
            "                                     task: mmimdb\n",
            "                                     task_type: classification\n",
            "                                     train_data_len: 8500\n",
            "                                     vocab: <__main__.Vocab object at 0x7f2628ed1a90>\n",
            "                                     vocab_sz: 30522\n",
            "                                     warmup: 0.1\n",
            "                                     weight_classes: 1\n",
            "INFO - 01/16/22 10:40:31 - 0:00:00 - MultimodalBertClf(\n",
            "                                       (enc): MultimodalBertEncoder(\n",
            "                                         (txt_embeddings): BertEmbeddings(\n",
            "                                           (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "                                           (position_embeddings): Embedding(512, 1024)\n",
            "                                           (token_type_embeddings): Embedding(2, 1024)\n",
            "                                           (LayerNorm): BertLayerNorm()\n",
            "                                           (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                         )\n",
            "                                         (img_embeddings): ImageBertEmbeddings(\n",
            "                                           (img_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "                                           (position_embeddings): Embedding(512, 1024)\n",
            "                                           (token_type_embeddings): Embedding(2, 1024)\n",
            "                                           (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "                                           (LayerNorm): BertLayerNorm()\n",
            "                                           (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                         )\n",
            "                                         (img_encoder): ImageEncoder(\n",
            "                                           (model): Sequential(\n",
            "                                             (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "                                             (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                             (2): ReLU(inplace=True)\n",
            "                                             (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "                                             (4): Sequential(\n",
            "                                               (0): Bottleneck(\n",
            "                                                 (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                                 (downsample): Sequential(\n",
            "                                                   (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (1): Bottleneck(\n",
            "                                                 (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (2): Bottleneck(\n",
            "                                                 (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (5): Sequential(\n",
            "                                               (0): Bottleneck(\n",
            "                                                 (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                                 (downsample): Sequential(\n",
            "                                                   (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                                   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (1): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (2): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (3): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (4): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (5): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (6): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (7): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (6): Sequential(\n",
            "                                               (0): Bottleneck(\n",
            "                                                 (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                                 (downsample): Sequential(\n",
            "                                                   (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                                   (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (1): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (2): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (3): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (4): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (5): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (6): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (7): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (8): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (9): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (10): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (11): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (12): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (13): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (14): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (15): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (16): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (17): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (18): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (19): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (20): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (21): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (22): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (23): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (24): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (25): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (26): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (27): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (28): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (29): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (30): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (31): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (32): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (33): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (34): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (35): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (7): Sequential(\n",
            "                                               (0): Bottleneck(\n",
            "                                                 (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                                 (downsample): Sequential(\n",
            "                                                   (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                                                   (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (1): Bottleneck(\n",
            "                                                 (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                               (2): Bottleneck(\n",
            "                                                 (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                                                 (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                                                 (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                                 (relu): ReLU(inplace=True)\n",
            "                                               )\n",
            "                                             )\n",
            "                                           )\n",
            "                                           (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                                         )\n",
            "                                         (encoder): BertEncoder(\n",
            "                                           (layer): ModuleList(\n",
            "                                             (0): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (1): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (2): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (3): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (4): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (5): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (6): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (7): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (8): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (9): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (10): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (11): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (12): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (13): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (14): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (15): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (16): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (17): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (18): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (19): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (20): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (21): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (22): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                             (23): BertLayer(\n",
            "                                               (attention): BertAttention(\n",
            "                                                 (self): BertSelfAttention(\n",
            "                                                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                                 (output): BertSelfOutput(\n",
            "                                                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                                   (LayerNorm): BertLayerNorm()\n",
            "                                                   (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                                 )\n",
            "                                               )\n",
            "                                               (intermediate): BertIntermediate(\n",
            "                                                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                                               )\n",
            "                                               (output): BertOutput(\n",
            "                                                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                                                 (LayerNorm): BertLayerNorm()\n",
            "                                                 (dropout): Dropout(p=0.1, inplace=False)\n",
            "                                               )\n",
            "                                             )\n",
            "                                           )\n",
            "                                         )\n",
            "                                         (pooler): BertPooler(\n",
            "                                           (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                                           (activation): Tanh()\n",
            "                                         )\n",
            "                                         (clf): Linear(in_features=1024, out_features=2, bias=True)\n",
            "                                       )\n",
            "                                       (clf): Linear(in_features=1024, out_features=2, bias=True)\n",
            "                                     )\n",
            "INFO - 01/16/22 10:40:41 - 0:00:11 - Training..\n",
            "100%|██████████| 1063/1063 [06:30<00:00,  2.73it/s]\n",
            "INFO - 01/16/22 10:47:21 - 0:06:50 - Train Loss: 0.0340\n",
            "INFO - 01/16/22 10:47:21 - 0:06:50 - Val: Loss: 0.70968 | Acc: 0.50600\n",
            "100%|██████████| 1063/1063 [06:32<00:00,  2.71it/s]\n",
            "INFO - 01/16/22 10:55:29 - 0:14:59 - Train Loss: 0.0328\n",
            "INFO - 01/16/22 10:55:29 - 0:14:59 - Val: Loss: 0.72897 | Acc: 0.50600\n",
            "100%|██████████| 1063/1063 [06:30<00:00,  2.72it/s]\n",
            "INFO - 01/16/22 11:02:40 - 0:22:10 - Train Loss: 0.0329\n",
            "INFO - 01/16/22 11:02:40 - 0:22:10 - Val: Loss: 0.76065 | Acc: 0.50600\n",
            "100%|██████████| 1063/1063 [06:29<00:00,  2.73it/s]\n",
            "INFO - 01/16/22 11:09:58 - 0:29:28 - Train Loss: 0.0328\n",
            "INFO - 01/16/22 11:09:58 - 0:29:28 - Val: Loss: 0.76193 | Acc: 0.50600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     4: reducing learning rate of group 0 to 5.0000e-05.\n",
            "Epoch     4: reducing learning rate of group 1 to 5.0000e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [06:26<00:00,  2.75it/s]\n",
            "INFO - 01/16/22 11:17:14 - 0:36:44 - Train Loss: 0.0326\n",
            "INFO - 01/16/22 11:17:14 - 0:36:44 - Val: Loss: 0.75524 | Acc: 0.50600\n",
            "100%|██████████| 1063/1063 [06:28<00:00,  2.74it/s]\n",
            "INFO - 01/16/22 11:24:31 - 0:44:00 - Train Loss: 0.0326\n",
            "INFO - 01/16/22 11:24:31 - 0:44:00 - Val: Loss: 0.71830 | Acc: 0.50600\n",
            "INFO - 01/16/22 11:25:02 - 0:44:32 - No improvement. Breaking out of loop.\n",
            "INFO - 01/16/22 11:25:30 - 0:44:59 - Test - test: Loss: 0.70964 | Acc: 0.51000\n",
            "INFO - 01/16/22 11:26:03 - 0:45:32 - Test - test_gt: Loss: 0.66284 | Acc: 0.62500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train_loader, val_loader, test_loaders = get_data_loaders(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96fnU8KOKMNG",
        "outputId": "50d3632f-df76-4e5e-cb49-bf42facdd69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 12/31/21 15:43:13 - 2:19:20 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO - 12/31/21 15:43:13 - 2:19:20 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "tokenizer = (\n",
        "        BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True).tokenize\n",
        "        if args.model in [\"bert\", \"mmbt\", \"concatbert\"]\n",
        "        else str.split\n",
        "    )\n",
        "transforms = get_transforms(args)\n",
        "vocab = get_vocab(args)\n",
        "args.vocab = vocab\n",
        "args.vocab_sz = vocab.vocab_sz\n",
        "args.n_classes = len(args.labels)\n",
        "\n",
        "collate = functools.partial(collate_fn, args=args)\n",
        "\n",
        "test_set_diff = JsonlDataset(\n",
        "       os.path.join( args.data_path, \"same_text_diff_image.jsonl\"),\n",
        "        tokenizer,\n",
        "        transforms,\n",
        "        vocab,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "test_loader_diff = DataLoader(\n",
        "        test_set_diff,\n",
        "        batch_size=args.batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=args.n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzmj22GdToYD",
        "outputId": "4cec527b-a954-4a6a-a922-1261107611f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 01/16/22 11:27:40 - 0:47:09 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO - 01/16/22 11:27:41 - 0:47:10 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(args)\n",
        "model.cuda()\n",
        "load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "3ufVaYlanKBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "id": "Ms1YrSJNOjLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def model_eval_v2(i_epoch, data, model, args, criterion, store_preds=False):\n",
        "    losses, preds, tgts = [], [], []\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, args, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            if args.task_type == \"multilabel\":\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy() > 0.5\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "\n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    if args.task_type == \"multilabel\":\n",
        "        tgts = np.vstack(tgts)\n",
        "        preds = np.vstack(preds)\n",
        "        metrics[\"macro_f1\"] = f1_score(tgts, preds, average=\"macro\")\n",
        "        metrics[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
        "    else:\n",
        "        tgts = [l for sl in tgts for l in sl]\n",
        "        preds = [l for sl in preds for l in sl]\n",
        "        metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "        metrics[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
        "        metrics[\"report\"] = classification_report(tgts, preds)\n",
        "        print(classification_report(tgts, preds))\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, args)\n",
        "    #return metrics,preds,tgts\n",
        "    #return metrics\n"
      ],
      "metadata": {
        "id": "Lci0US9XE4Xw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader_diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al-0oiy1VbpC",
        "outputId": "603adeb6-485a-4ba3-a570-df11347a7df3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f2626c561d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = get_criterion(args) #criteria for loss\n",
        "\n",
        "model_eval_v2(\n",
        "            np.inf, test_loader_diff, model, args, criterion, store_preds=True\n",
        "        )"
      ],
      "metadata": {
        "id": "z7Ap0FuWPmi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421ae5b3-1fe5-4dba-f700-3bcd58fb8d11"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70       572\n",
            "           1       0.00      0.00      0.00       484\n",
            "\n",
            "    accuracy                           0.54      1056\n",
            "   macro avg       0.27      0.50      0.35      1056\n",
            "weighted avg       0.29      0.54      0.38      1056\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "tokenizer = (\n",
        "        BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True).tokenize\n",
        "        if args.model in [\"bert\", \"mmbt\", \"concatbert\"]\n",
        "        else str.split\n",
        "    )\n",
        "transforms = get_transforms(args)\n",
        "vocab = get_vocab(args)\n",
        "args.vocab = vocab\n",
        "args.vocab_sz = vocab.vocab_sz\n",
        "args.n_classes = len(args.labels)\n",
        "\n",
        "collate = functools.partial(collate_fn, args=args)\n",
        "\n",
        "test_set_shuff = JsonlDataset(\n",
        "       os.path.join( args.data_path, \"shuffled.jsonl\"),\n",
        "        tokenizer,\n",
        "        transforms,\n",
        "        vocab,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "test_loader_shuff = DataLoader(\n",
        "        test_set_shuff,\n",
        "        batch_size=args.batch_sz,\n",
        "        shuffle=False,\n",
        "        num_workers=args.n_workers,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdnX017W5bM",
        "outputId": "12625fe1-7164-4b0e-da6f-5688d74cb4c3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 01/16/22 11:30:28 - 0:49:57 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO - 01/16/22 11:30:29 - 0:49:58 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_eval_v2(\n",
        "            np.inf, test_loader_shuff, model, args, criterion, store_preds=True\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoEITAqiZ1Ud",
        "outputId": "193e6379-0978-40cc-efc8-59617774a8d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77      1250\n",
            "           1       0.00      0.00      0.00       750\n",
            "\n",
            "    accuracy                           0.62      2000\n",
            "   macro avg       0.31      0.50      0.38      2000\n",
            "weighted avg       0.39      0.62      0.48      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vjmPlYfFaLm9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}